{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import get_num_lines, get_vocab, embed_sequence, get_word2idx_idx2word, get_embedding_matrix\n",
    "# from util import TextDatasetWithGloveElmoSuffix as TextDataset\n",
    "# from util import evaluate\n",
    "# from model import RNNSequenceClassifier\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "1. Data pre-processing\n",
    "\"\"\"\n",
    "'''\n",
    "1.1 \n",
    "get rev_id --> label as a dictionary:\n",
    "    rev_id: string to indicate the id of the comment\n",
    "    label: int 1 or 0\n",
    "'''\n",
    "id2label = {}\n",
    "with open('../aggression_dataset/aggression_annotations.tsv') as f:\n",
    "    lines = csv.reader(f, delimiter='\\t')\n",
    "    next(lines, None)  # skip the headers\n",
    "    for line in lines:\n",
    "        rev_id = line[0]\n",
    "        # worker_id = line[1]\n",
    "        aggression_label = int(float(line[2]))\n",
    "        # aggression_score = float(line[3])\n",
    "        id2label[rev_id] = aggression_label                 \n",
    "'''\n",
    "1.2 \n",
    "get raw dataset as three list with given train/dev/test split:\n",
    "  Each element is a triple:\n",
    "    comment: the text needed to be classified (removed NEWLINE_TOKEN)\n",
    "    rev_id: string\n",
    "    label: int 1 or 0\n",
    "'''\n",
    "\n",
    "\n",
    "raw_train = []\n",
    "raw_dev = []\n",
    "raw_test = []\n",
    "with open('../aggression_dataset/aggression_annotated_comments.tsv') as f:\n",
    "    lines = csv.reader(f, delimiter='\\t')\n",
    "    next(lines, None)  # skip the headers\n",
    "    for line in lines:\n",
    "        rev_id = line[0]\n",
    "        comment = line[1].replace('NEWLINE_TOKEN', '').lower()\n",
    "        split = line[6]\n",
    "        if split == 'train':\n",
    "            raw_train.append([comment, rev_id, id2label[rev_id]])\n",
    "        elif split == 'dev':\n",
    "            raw_dev.append([comment,rev_id,  id2label[rev_id]])\n",
    "        else:\n",
    "            raw_test.append([comment, rev_id, id2label[rev_id]])     \n",
    "            \n",
    "# datset split: train, dev, test:  69526 23160 23178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  2857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2196017 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1030/2196017 [00:00<03:35, 10173.97it/s]\u001b[A\n",
      "  0%|          | 2851/2196017 [00:00<02:34, 14172.80it/s]\u001b[A\n",
      "  0%|          | 5089/2196017 [00:00<02:09, 16874.36it/s]\u001b[A\n",
      "  0%|          | 7595/2196017 [00:00<01:55, 18916.37it/s]\u001b[A\n",
      "  0%|          | 10262/2196017 [00:00<01:46, 20458.38it/s]\u001b[A\n",
      "  1%|          | 13033/2196017 [00:00<01:40, 21663.39it/s]\u001b[A\n",
      "  1%|          | 15880/2196017 [00:00<01:36, 22632.15it/s]\u001b[A\n",
      "  1%|          | 18656/2196017 [00:00<01:33, 23271.65it/s]\u001b[A\n",
      "  1%|          | 21358/2196017 [00:00<01:31, 23687.66it/s]\u001b[A\n",
      "  1%|          | 24213/2196017 [00:01<01:29, 24172.39it/s]\u001b[A\n",
      "  1%|          | 27237/2196017 [00:01<01:27, 24722.66it/s]\u001b[A\n",
      "  1%|▏         | 30177/2196017 [00:01<01:26, 25111.99it/s]\u001b[A\n",
      "  2%|▏         | 33075/2196017 [00:01<01:25, 25406.29it/s]\u001b[A\n",
      "  2%|▏         | 35917/2196017 [00:01<01:24, 25623.50it/s]\u001b[A\n",
      "  2%|▏         | 38916/2196017 [00:01<01:23, 25913.94it/s]\u001b[A\n",
      "  2%|▏         | 41867/2196017 [00:01<01:22, 26136.84it/s]\u001b[A\n",
      "  2%|▏         | 44873/2196017 [00:01<01:21, 26368.29it/s]\u001b[A\n",
      "  2%|▏         | 47810/2196017 [00:01<01:20, 26530.59it/s]\u001b[A\n",
      "  2%|▏         | 50745/2196017 [00:01<01:20, 26660.13it/s]\u001b[A\n",
      "  2%|▏         | 53728/2196017 [00:02<01:19, 26811.76it/s]\u001b[A\n",
      "  3%|▎         | 56666/2196017 [00:02<01:19, 26934.05it/s]\u001b[A\n",
      "  3%|▎         | 59604/2196017 [00:02<01:19, 26981.60it/s]\u001b[A\n",
      "  3%|▎         | 62624/2196017 [00:02<01:18, 27121.82it/s]\u001b[A\n",
      "  3%|▎         | 65611/2196017 [00:02<01:18, 27230.46it/s]\u001b[A\n",
      "  3%|▎         | 68572/2196017 [00:02<01:17, 27326.59it/s]\u001b[A\n",
      "  3%|▎         | 71532/2196017 [00:02<01:17, 27415.80it/s]\u001b[A\n",
      "  3%|▎         | 74516/2196017 [00:02<01:17, 27505.15it/s]\u001b[A\n",
      "  4%|▎         | 77479/2196017 [00:02<01:16, 27553.80it/s]\u001b[A\n",
      "  4%|▎         | 80497/2196017 [00:02<01:16, 27641.29it/s]\u001b[A\n",
      "  4%|▍         | 83539/2196017 [00:03<01:16, 27732.88it/s]\u001b[A\n",
      "  4%|▍         | 86525/2196017 [00:03<01:15, 27788.62it/s]\u001b[A\n",
      "  4%|▍         | 89530/2196017 [00:03<01:15, 27847.11it/s]\u001b[A\n",
      "  4%|▍         | 92535/2196017 [00:03<01:15, 27915.38it/s]\u001b[A\n",
      "  4%|▍         | 95518/2196017 [00:03<01:15, 27965.47it/s]\u001b[A\n",
      "  4%|▍         | 98495/2196017 [00:03<01:14, 28009.05it/s]\u001b[A\n",
      "  5%|▍         | 101530/2196017 [00:03<01:14, 28071.56it/s]\u001b[A\n",
      "  5%|▍         | 104516/2196017 [00:03<01:14, 28106.78it/s]\u001b[A\n",
      "  5%|▍         | 107487/2196017 [00:03<01:14, 28113.58it/s]\u001b[A\n",
      "  5%|▌         | 110555/2196017 [00:03<01:14, 28176.46it/s]\u001b[A\n",
      "  5%|▌         | 113525/2196017 [00:04<01:13, 28207.07it/s]\u001b[A\n",
      "  5%|▌         | 116559/2196017 [00:04<01:13, 28257.97it/s]\u001b[A\n",
      "  5%|▌         | 119542/2196017 [00:04<01:13, 28284.26it/s]\u001b[A\n",
      "  6%|▌         | 122547/2196017 [00:04<01:13, 28322.00it/s]\u001b[A\n",
      "  6%|▌         | 125524/2196017 [00:04<01:13, 28345.82it/s]\u001b[A\n",
      "  6%|▌         | 128488/2196017 [00:04<01:12, 28373.52it/s]\u001b[A\n",
      "  6%|▌         | 131448/2196017 [00:04<01:12, 28387.29it/s]\u001b[A\n",
      "  6%|▌         | 134393/2196017 [00:04<01:12, 28392.21it/s]\u001b[A\n",
      "  6%|▋         | 137319/2196017 [00:04<01:12, 28410.69it/s]\u001b[A\n",
      "  6%|▋         | 140241/2196017 [00:04<01:12, 28423.84it/s]\u001b[A\n",
      "  7%|▋         | 143243/2196017 [00:05<01:12, 28454.93it/s]\u001b[A\n",
      "  7%|▋         | 146282/2196017 [00:05<01:11, 28490.60it/s]\u001b[A\n",
      "  7%|▋         | 149252/2196017 [00:05<01:11, 28507.01it/s]\u001b[A\n",
      "  7%|▋         | 152239/2196017 [00:05<01:11, 28532.76it/s]\u001b[A\n",
      "  7%|▋         | 155212/2196017 [00:05<01:11, 28554.51it/s]\u001b[A\n",
      "  7%|▋         | 158197/2196017 [00:05<01:11, 28578.59it/s]\u001b[A\n",
      "  7%|▋         | 161191/2196017 [00:05<01:11, 28602.84it/s]\u001b[A\n",
      "  7%|▋         | 164171/2196017 [00:05<01:10, 28621.03it/s]\u001b[A\n",
      "  8%|▊         | 167148/2196017 [00:05<01:10, 28639.86it/s]\u001b[A\n",
      "  8%|▊         | 170123/2196017 [00:05<01:10, 28652.12it/s]\u001b[A\n",
      "  8%|▊         | 173087/2196017 [00:06<01:10, 28661.77it/s]\u001b[A\n",
      "  8%|▊         | 176088/2196017 [00:06<01:10, 28682.40it/s]\u001b[A\n",
      "  8%|▊         | 179053/2196017 [00:06<01:10, 28693.21it/s]\u001b[A\n",
      "  8%|▊         | 182012/2196017 [00:06<01:10, 28702.21it/s]\u001b[A\n",
      "  8%|▊         | 184988/2196017 [00:06<01:10, 28716.95it/s]\u001b[A\n",
      "  9%|▊         | 188054/2196017 [00:06<01:09, 28746.35it/s]\u001b[A\n",
      "  9%|▊         | 191059/2196017 [00:06<01:09, 28766.92it/s]\u001b[A\n",
      "  9%|▉         | 194078/2196017 [00:06<01:09, 28784.27it/s]\u001b[A\n",
      "  9%|▉         | 197088/2196017 [00:06<01:09, 28806.22it/s]\u001b[A\n",
      "  9%|▉         | 200091/2196017 [00:06<01:09, 28818.24it/s]\u001b[A\n",
      "  9%|▉         | 203084/2196017 [00:07<01:09, 28789.04it/s]\u001b[A\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gl/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/gl/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/Users/gl/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████| 2196017/2196017 [01:08<00:00, 32100.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pre-trained word vectors loaded:  1933\n",
      "Embeddings mean:  -0.0005043626297265291\n",
      "Embeddings stdev:  0.3630717098712921\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2. Data preparation\n",
    "\"\"\"\n",
    "'''\n",
    "2. 1\n",
    "get vocabulary and glove embeddings in raw dataset \n",
    "'''\n",
    "# vocab is a set of words\n",
    "vocab = get_vocab(raw_train + raw_dev + raw_test)\n",
    "# two dictionaries. <PAD>: 0, <UNK>: 1\n",
    "word2idx, idx2word = get_word2idx_idx2word(vocab)\n",
    "# glove_embeddings a nn.Embeddings\n",
    "glove_embeddings = get_embedding_matrix(word2idx, idx2word, normalization=False)\n",
    "# elmo_embeddings\n",
    "# elmos_train_vua = h5py.File('../elmo/VUA_train.hdf5', 'r')\n",
    "# elmos_val_vua = h5py.File('../elmo/VUA_val.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: dimension 0 out of range of 0D tensor at /Users/gl/pytorch/aten/src/TH/generic/THTensor.c:24",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6010ec760354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0melmos_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m embedded_train = [[embed_sequence(example[0], word2idx, glove_embeddings, elmos_train), example[2]]\n\u001b[0;32m----> 8\u001b[0;31m                       for example in raw_train]\n\u001b[0m\u001b[1;32m      9\u001b[0m embedded_val = [[embed_sequence(example[0], word2idx, glove_embeddings, elmos_dev), example[2]]\n\u001b[1;32m     10\u001b[0m                     for example in raw_dev]\n",
      "\u001b[0;32m<ipython-input-20-6010ec760354>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0melmos_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m embedded_train = [[embed_sequence(example[0], word2idx, glove_embeddings, elmos_train), example[2]]\n\u001b[0;32m----> 8\u001b[0;31m                       for example in raw_train]\n\u001b[0m\u001b[1;32m      9\u001b[0m embedded_val = [[embed_sequence(example[0], word2idx, glove_embeddings, elmos_dev), example[2]]\n\u001b[1;32m     10\u001b[0m                     for example in raw_dev]\n",
      "\u001b[0;32m<ipython-input-19-16269e346fca>\u001b[0m in \u001b[0;36membed_sequence\u001b[0;34m(sequence, word2idx, glove_embeddings, elmo_embeddings)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mindexed_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# glove_part has shape: (seq_len, glove_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mglove_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglove_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# 2. embed the sequence by elmo vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/thnn/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, indices, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: dimension 0 out of range of 0D tensor at /Users/gl/pytorch/aten/src/TH/generic/THTensor.c:24"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2. 2\n",
    "embed the datasets\n",
    "'''\n",
    "elmos_train = None\n",
    "elmos_val = None\n",
    "embedded_train = [[embed_sequence(example[0], word2idx, glove_embeddings, elmos_train), example[2]]\n",
    "                      for example in raw_train]\n",
    "embedded_val = [[embed_sequence(example[0], word2idx, glove_embeddings, elmos_dev), example[2]]\n",
    "                    for example in raw_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
